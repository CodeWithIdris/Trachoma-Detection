{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet101, VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "header1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1325 images belonging to 2 classes.\n",
      "Found 331 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Assuming the dataset is structured with subdirectories for each class (e.g., 'Trachoma' and 'Healthy')\n",
    "data_dir = r'C:\\Users\\Habeeb\\Downloads\\Finale\\dataset'\n",
    "\n",
    "# ImageDataGenerator for preprocessing and data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split = 0.2,  # 20% of the data for validation\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    "    \n",
    ")\n",
    "\n",
    "# Training data generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size = (224, 224),  # Resize images to 224x224\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary',\n",
    "    subset = 'training'  # Use this subset for training\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary',\n",
    "    subset = 'validation'  # Use this subset for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Build CNN model ResNet101 and VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_resnet = ModelCheckpoint(\"resnet101_best_model.keras\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "checkpoint_vgg16 = ModelCheckpoint(\"vgg16_best_model.keras\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "# ResNet101\n",
    "def create_resnet101_model(input_shape):\n",
    "    base_model = ResNet101(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "resnet101_model = create_resnet101_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16\n",
    "def create_vgg16_model(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "vgg16_model = create_vgg16_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habeeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8/41\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:01\u001b[0m 31s/step - accuracy: 0.4880 - loss: 0.8114"
     ]
    }
   ],
   "source": [
    "# Training the ResNet101 model\n",
    "history_resnet101 = resnet101_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=50,  # Increase the number of epochs\n",
    "    callbacks=[checkpoint_resnet, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the VGG16 model\n",
    "history_vgg16 = vgg16_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=50,  # Increase the number of epochs\n",
    "    callbacks=[checkpoint_vgg16, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the ResNet101 model\n",
    "val_loss_resnet101, val_accuracy_resnet101 = resnet101_model.evaluate(validation_generator)\n",
    "print(f'ResNet101 Validation Loss: {val_loss_resnet101}')\n",
    "print(f'ResNet101 Validation Accuracy: {val_accuracy_resnet101}')\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "val_predictions_resnet101 = resnet101_model.predict(validation_generator)\n",
    "val_predictions_resnet101 = (val_predictions_resnet101 > 0.5).astype(int)  # Convert probabilities to binary output\n",
    "\n",
    "val_labels = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the VGG16 model\n",
    "\n",
    "val_loss_vgg16, val_accuracy_vgg16 = vgg16_model.evaluate(validation_generator)\n",
    "print(f'VGG16 Validation Loss: {val_loss_vgg16}')\n",
    "print(f'VGG16 Validation Accuracy: {val_accuracy_vgg16}')\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "val_predictions_vgg16 = vgg16_model.predict(validation_generator)\n",
    "val_predictions_vgg16 = (val_predictions_vgg16 > 0.5).astype(int)  # Convert probabilities to binary output\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(val_labels, val_predictions_vgg16, target_names=class_labels))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix_vgg16 = confusion_matrix(val_labels, val_predictions_vgg16)\n",
    "print(conf_matrix_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(val_labels, val_predictions_resnet101, target_names=class_labels))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix_resnet101 = confusion_matrix(val_labels, val_predictions_resnet101)\n",
    "print(conf_matrix_resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the VGG16 model\n",
    "val_loss_vgg16, val_accuracy_vgg16 = vgg16_model.evaluate(validation_generator)\n",
    "print(f'VGG16 Validation Loss: {val_loss_vgg16}')\n",
    "print(f'VGG16 Validation Accuracy: {val_accuracy_vgg16}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report and confusion matrix\n",
    "val_predictions_vgg16 = vgg16_model.predict(validation_generator)\n",
    "val_predictions_vgg16 = (val_predictions_vgg16 > 0.5).astype(int)  # Convert probabilities to binary output\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(val_labels, val_predictions_vgg16, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix_vgg16 = confusion_matrix(val_labels, val_predictions_vgg16)\n",
    "print(conf_matrix_resnet101)\n",
    "\n",
    "# Plot confusion matrix for ResNet101\n",
    "plt.matshow(conf_matrix_resnet101, cmap='coolwarm')\n",
    "plt.title('ResNet101 Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('resnet101.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for VGG16\n",
    "plt.matshow(conf_matrix_vgg16, cmap='coolwarm')\n",
    "plt.title('VGG16 Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('vgg16_confusion_matrix.png')  # Save the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values for ResNet101\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_resnet101.history['accuracy'])\n",
    "plt.plot(history_resnet101.history['val_accuracy'])\n",
    "plt.title('ResNet101 Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('resnet101_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values for ResNet101\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_resnet101.history['loss'])\n",
    "plt.plot(history_resnet101.history['val_loss'])\n",
    "plt.title('ResNet101 Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('resnet101_loss.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for VGG16\n",
    "plt.matshow(conf_matrix_vgg16, cmap='coolwarm')\n",
    "plt.title('VGG16 Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('vgg16_confusion_matrix.png')  # Save the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values for VGG16\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_vgg16.history['accuracy'])\n",
    "plt.plot(history_vgg16.history['val_accuracy'])\n",
    "plt.title('VGG16 Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('vgg16_accuracy.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values for VGG16\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_vgg16.history['loss'])\n",
    "plt.plot(history_vgg16.history['val_loss'])\n",
    "plt.title('VGG16 Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('vgg16_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Get true labels\n",
    "true_labels = validation_generator.classes\n",
    "\n",
    "# Get predicted probabilities\n",
    "# For binary classification, use the probability of the positive class (class 1)\n",
    "predicted_probabilities_resnet101 = resnet101_model.predict(validation_generator)\n",
    "predicted_probabilities_vgg16 = vgg16_model.predict(validation_generator)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc_resnet101 = roc_auc_score(true_labels, predicted_probabilities_resnet101)\n",
    "roc_auc_vgg16 = roc_auc_score(true_labels, predicted_probabilities_vgg16)\n",
    "\n",
    "print(f'ROC AUC for ResNet101: {roc_auc_resnet101}')\n",
    "print(f'ROC AUC for VGG16: {roc_auc_vgg16}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
